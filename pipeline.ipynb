{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install kfp >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_url = \"https://raw.githubusercontent.com/oneconvergence/dkube/master/components/\"\n",
    "dkube_preprocessing_op = kfp.components.load_component_from_url(components_url + \"preprocess/component.yaml\")\n",
    "dkube_training_op = kfp.components.load_component_from_url(components_url + \"training/component.yaml\")\n",
    "dkube_storage_op  = kfp.components.load_component_from_url(components_url + \"storage/component.yaml\")\n",
    "dkube_submit_op = kfp.components.load_component_from_url(components_url + \"submit/component.yaml\")\n",
    "runid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='dkube-titanic-pl',\n",
    "    description='example titanic pipeline to submit to leaderboard'\n",
    ")\n",
    "def titanic_pipeline(token, project_id):\n",
    "\n",
    "    preprocessing = dkube_preprocessing_op(token, '{\"image\":\"docker.io/ocdr/d3-datascience-tf-cpu:fs-v1.14\"}',\n",
    "                                           program=\"titanic\", run_script=\"python preprocessing.py --train_fs titanic-train-fs --test_fs titanic-test-fs\",\n",
    "                                           datasets=json.dumps([\"titanic-train\", \"titanic-test\"]), \n",
    "                                           output_featuresets=json.dumps([\"titanic-train-fs\", \"titanic-test-fs\"]),\n",
    "                                           input_dataset_mounts=json.dumps([\"/opt/dkube/input/train\", \"/opt/dkube/input/test\"]), \n",
    "                                           output_featureset_mounts=json.dumps([\"/opt/dkube/output/train\", \"/opt/dkube/output/test\"])\n",
    "                                            )\n",
    "\n",
    "    with kfp.dsl.ExitHandler(exit_op=dkube_storage_op(\"reclaim\", token, namespace=\"kubeflow\",uid=\"{{workflow.uid}}\")):\n",
    "        input_volumes = json.dumps([\"{{workflow.uid}}-dataset@dataset://ocdkube:titanic-test\",\n",
    "                                    \"{{workflow.uid}}-model@model://titanic\",\n",
    "                                    \"{{workflow.uid}}-code@program://titanic\"\n",
    "                                    ])\n",
    "        train       = dkube_training_op(token, '{\"image\":\"docker.io/ocdr/d3-datascience-tf-cpu:fs-v1.14\"}',\n",
    "                                    framework=\"sklearn\", version=\"0.23.2\",\n",
    "                                    program=\"titanic\", run_script=\"python training.py\",\n",
    "                                    featuresets=json.dumps([\"titanic-train-fs\", \"titanic-test-fs\"]), outputs='[\"titanic\"]',\n",
    "                                    input_featureset_mounts='[\"/titanic-train\",\"/titanic-test\"]',\n",
    "                                    output_mounts='[\"/model\"]').after(preprocessing)\n",
    "        storage  = dkube_storage_op(\"export\", token, namespace=\"kubeflow\", input_volumes=input_volumes).after(train)\n",
    "\n",
    "    \n",
    "        predict_op = kfp.dsl.ContainerOp(\n",
    "            name=\"predict\",\n",
    "            image=\"ocdr/dkube-datascience-tf-cpu:v2.0.0\",\n",
    "            command=[\"python\", \"/code/predict.py\"],\n",
    "            pvolumes={\"/titanic-test/\": kfp.dsl.PipelineVolume(pvc=\"{{workflow.uid}}-dataset\"),\n",
    "                     \"/model/\": kfp.dsl.PipelineVolume(pvc=\"{{workflow.uid}}-model\"),\n",
    "                     \"/code/\": kfp.dsl.PipelineVolume(pvc=\"{{workflow.uid}}-code\")\n",
    "                     },\n",
    "            file_outputs={\"output\": \"/tmp/prediction.csv\"},\n",
    "        ).after(storage)\n",
    "\n",
    "        predictions = kfp.dsl.InputArgumentPath(predict_op.outputs[\"output\"])\n",
    "\n",
    "        submit = dkube_submit_op(token, project_id, predictions=predict_op.outputs[\"output\"]).after(predict_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token  = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\")\n",
    "client = kfp.Client(existing_token=token)\n",
    "#Replace [titanic] & wprz8s with your project name and id respectively.\n",
    "client.create_run_from_pipeline_func(titanic_pipeline, run_name=\"[titanic] Run\" + str(runid), arguments={\"token\":token,\"project_id\":\"ynli7c\"})\n",
    "runid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
